{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Premise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember this image? Well, each part interacts with each other, but fundamentally can be written into individual python scripts for improved organization\n",
    "\n",
    "<img src=\"Workflow.png\" alt=\"The WorkFlow\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, no new code in this section! Just pure organization and separating all the parts of our machine learning process from the last part, custom datasets\n",
    "\n",
    "<img src=\"Division.png\" alt=\"The WorkFlow\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the end, we can just use a 1 liner like this, and directly make a model and train it with these hyper parameters\n",
    "\n",
    "<img src=\"Command Line.png\" alt=\"The WorkFlow\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's how the real folks do it in the industry, they divide their python files to take different parts in this machine learning madness\n",
    "\n",
    "It's also good for the reusability of the code, since as scripts, we can just drop and play around with them on different models\n",
    "\n",
    "<img src=\"TorchVision.png\" alt=\"The WorkFlow\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Divsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we get the logic of the code down, we will chuck all the essential code (from custom datasets) into python scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "1. Getting Data\n",
    "    - Download the data with (`Requests`) then unzip it with (`Zipfile`)\n",
    "    - Set up a training data directory, and testing data directory and split data 80/20 as (`Training/Testing)\n",
    "\n",
    "2. Loading Data\n",
    "    - Load the data with torchvision's default (`Dataset`) and (`Dataloader`), 1 training 1 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "1. Make Model\n",
    "    - Define the model class with (`nn.Module`), write the (`_init_`) and (`forward`) function\n",
    "\n",
    "2. Train/Test Model\n",
    "    - Define the (`Loss Function`) and (`Optimizer`)\n",
    "    - Write out a (`training_step`), and a (`testing step`)\n",
    "    - Write out the (`training loop`)\n",
    "\n",
    "3. Save/Load Model\n",
    "    - Define a function that saves a PyTorch model to a model foler, with (`Pathlib`)\n",
    "    - Also, another function that loads a PyTorch model, for usage or further training\n",
    "\n",
    "4. Use Model\n",
    "    - Define a function that performs a forward pass on an existing, trained Pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be different in detail of implementation as python scripts, but the essence is the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The library that allows us to interact with web services and APIs\n",
    "import requests\n",
    "\n",
    "#As the name suggests... allows us to unzip or zip files\n",
    "import zipfile\n",
    "\n",
    "#Setting up directories, folders, getting things to places\n",
    "from pathlib import Path\n",
    "\n",
    "#For Deleting the Zip File After Download\n",
    "import os\n",
    "\n",
    "\n",
    "#Setup path to a folder\n",
    "data_path = Path(\"Data/\")\n",
    "\n",
    "\n",
    "#Creating data folder\n",
    "if data_path.is_dir():\n",
    "    print(f\"{data_path} directory already exists, skipping download\")\n",
    "else:\n",
    "    print(f\"{data_path} does not exist, creating directory\")\n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    #Downloading Data Zip file, wb means write binary\n",
    "    with open(data_path/\"pizza_steak_sushi.zip\",\"wb\") as a:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading image data...\")\n",
    "        a.write(request.content)\n",
    "    \n",
    "    \n",
    "    #Unzipping Files in Zip\n",
    "    with zipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\", \"r\") as images:\n",
    "        print(\"Unzipping Image Data\")\n",
    "        images.extractall(data_path)\n",
    "\n",
    "\n",
    "    # Delete the zip file\n",
    "    zip_file_path = data_path / \"pizza_steak_sushi.zip\"\n",
    "    try:\n",
    "        os.remove(zip_file_path)\n",
    "        print(f\"{zip_file_path} deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dir = data_path/\"train\"\n",
    "test_dir = data_path/\"test\"\n",
    "\n",
    "\n",
    "#This step describes the transformations of images before turning into tensors\n",
    "data_transform = transforms.Compose([\n",
    "\n",
    "    #Change the size\n",
    "    transforms.Resize(size=(128,128)),\n",
    "\n",
    "    #Random application of a shit ton of jizz jazz\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "\n",
    "    #Turns the image into a tensor\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#target folder of images, and transforms to perform on data (images)\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform) \n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
    "\n",
    "#batch size is how many samples in a batch\n",
    "#num workers is how many cores you want the cpu to be running this dataloader on\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=5, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=1, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be different in detail of implementation as python scripts, but the essence is the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "        See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "        There are no parameters that you can alter here for creating the neural network\n",
    "\n",
    "        It is defined as 3 consecutive 2D convolutional blocks, each block with (Conv2d, LeakyRelu, Conv2d, LeakyRelu, MaxPool2d)\n",
    "        In channels = 10, Out channels = 10, kernel_size = 3, stride = 1, padding = 1\n",
    "\n",
    "        Then a sequential layer with (Flatten, Linear, Softmax)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #The in channels is no longer 1, as now we have 3 channels RGB from our input\n",
    "        self.conv_b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        #again, we don't know the input feature size, so we just run and see the tensor error, then replace it with the correct number\n",
    "        self.end_classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2560, out_features=3), \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    #ok... it's not really just a image, when through all those convolution layers there's like 10 \"feature\" images running parallel\n",
    "    def forward(self, image):\n",
    "        return self.end_classifier(self.conv_b3(self.conv_b2(self.conv_b1(image))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train_step(model, data_loader, loss_fn, optimizer, device, epoch):\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (image, label) in enumerate(data_loader):\n",
    "\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        prediction = model(image)\n",
    "\n",
    "        loss = loss_fn(prediction, label)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        prediction_label = torch.argmax(prediction, dim=1)\n",
    "        train_acc += (prediction_label == label).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Epoch: {epoch + 1} | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "def test_step(model, data_loader, loss_fn, device, epoch):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (image, label) in enumerate(data_loader):\n",
    "\n",
    "           image, label = image.to(device), label.to(device)\n",
    "           prediction = model(image)\n",
    "\n",
    "           loss = loss_fn(prediction, label)\n",
    "           test_loss += loss.item()\n",
    "\n",
    "           prediction_label = torch.argmax(prediction, dim=1)\n",
    "           test_acc += (prediction_label == label).sum().item()\n",
    "\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "    print(f\"Epoch: {epoch + 1} | Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train, test, loss_fn, optimizer, device, epochs):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_step(model, train, loss_fn, optimizer, device, epoch)\n",
    "        test_step(model, test, loss_fn, device, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def save_model(model, model_name):\n",
    "\n",
    "    #Create directory\n",
    "    model_path = Path(\"models\")\n",
    "    model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Create saving path, usually pytorch files are called \"pth\"\n",
    "    model_name = model_name\n",
    "    model_save_path = model_path / model_name\n",
    "\n",
    "    #Saving the state dict\n",
    "    print(f\"Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(), f=model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_class, model_name):\n",
    "\n",
    "    #we'll need to create a new model and load the saved state_dict() into the new model\n",
    "    model = model_class()\n",
    "\n",
    "    #loading the saved state dict from the new model, with torch.load()\n",
    "    model.load_state_dict(torch.load(f=model_name))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
